{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled19.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPiCEXRdV668BZTulTThsNj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Minsoo1036/DeepLearning-and-PyTorch/blob/main/Colab_rnn_lstm_gru_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpYdeTz1_ePs",
        "outputId": "7c316e0a-8a28-4419-cef1-435616a8eb9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         1.5.1\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.3.1\n",
            "torchvision                   0.6.1\n"
          ]
        }
      ],
      "source": [
        "! pip list | grep \"torch\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade torch==1.5.1"
      ],
      "metadata": {
        "id": "zGUYUcDWDNA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade torchsummary==1.5.1"
      ],
      "metadata": {
        "id": "eFPqlU_1DNEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade torchtext==0.3.1"
      ],
      "metadata": {
        "id": "a0mm33-jDNHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install --upgrade torchvision==0.6.1"
      ],
      "metadata": {
        "id": "k9tIdpz4DNJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip list | grep \"torch\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uh-kFmC8DNMT",
        "outputId": "052d5283-7e50-49fc-fc8d-86db65d7f8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         1.5.1\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.3.1\n",
            "torchvision                   0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVhLr5hXC0iE",
        "outputId": "84ad335d-c9a3-494f-8b45-19be6f3a5b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -c 'import torch; print(torch.__version__) '"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xCwt5dIC0pu",
        "outputId": "95129f62-f872-4d95-b009-f11ebc76ffd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -d /usr/local/cuda-*\n",
        "!which nvcc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUwOgWFZC5U8",
        "outputId": "3d7d0a9e-96a8-40ba-93f0-20caf2ce5ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/cuda-10.0  /usr/local/cuda-11    /usr/local/cuda-11.1\n",
            "/usr/local/cuda-10.1  /usr/local/cuda-11.0\n",
            "/usr/local/cuda/bin/nvcc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "p = os.getenv('PATH')\n",
        "ld = os.getenv('LD_LIBRARY_PATH')\n",
        "os.environ['PATH'] = f\"/usr/local/cuda-10.1/bin:{p}\"\n",
        "os.environ['LD_LIBRARY_PATH'] = f\"/usr/local/cuda-10.1/lib64:{ld}\"\n",
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3bnsMnbC5X5",
        "outputId": "98dca537-b024-4f33-a281-2a2bece9087b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "assert torch.__version__.startswith(\"1.5.1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lMa6oWzFOFM",
        "outputId": "f2a63432-6826-4676-ee6e-669f625385e4"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.1 True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip list | grep \"torch\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qjfC_DRA5BV",
        "outputId": "89eed71b-907e-4dcc-f26e-b4a3842ad5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch                         1.5.1\n",
            "torchaudio                    0.11.0+cu113\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.3.1\n",
            "torchvision                   0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext import datasets"
      ],
      "metadata": {
        "id": "K_h2rhvf_hWv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data Setting\n",
        "TEXT = data.Field(batch_first = True,\n",
        "                  fix_length = 500,\n",
        "                  tokenize=str.split,\n",
        "                  pad_first=True,\n",
        "                  pad_token='[PAD]',\n",
        "                  unk_token='[UNK]')\n",
        "\n",
        "LABEL = data.LabelField(dtype=torch.float)\n",
        "\n",
        "train_data, test_data = datasets.IMDB.splits(text_field = TEXT, \n",
        "                                             label_field = LABEL)"
      ],
      "metadata": {
        "id": "y78lyNKd_hZb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Length\n",
        "print(f'Train Data Length : {len(train_data.examples)}')\n",
        "print(f'Test Data Length : {len(test_data.examples)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlRK_XZz_hcE",
        "outputId": "6695d254-7f49-431f-fce3-ed84457f890f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data Length : 25000\n",
            "Test Data Length : 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Fields\n",
        "train_data.fields"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhE7ANZb_heg",
        "outputId": "40140b96-88b5-4713-c58f-577bf1da8ded"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': <torchtext.data.field.LabelField at 0x7f5795441190>,\n",
              " 'text': <torchtext.data.field.Field at 0x7f57a5a28c50>}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Sample\n",
        "print('---- Data Sample ----')\n",
        "print('Input : ')\n",
        "print(' '.join(vars(train_data.examples[1])['text']),'\\n')\n",
        "print('Label : ')\n",
        "print(vars(train_data.examples[1])['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URKZZEWj_hhL",
        "outputId": "1f71ec05-99df-43b2-8d79-3e640c215d04"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Data Sample ----\n",
            "Input : \n",
            "I don't think most of us would tend to apply the term \"must-see\" to action films, but I was very impressed at how good this film was and it deservedly gets the \"must-see\" stamp from me.<br /><br />Mandy played by Shannon Lee (daughter of the late and great Bruce Lee and sister of the late Brandon Lee) is recruited by Martin, a professional thief to help pull off a diamond heist at a museum for a criminal syndicate, and get rewarded handsomely for it. Little do they know that another pair of thieves (Lucy and Tommy, a pair of lovebirds), who were spurned earlier by Mandy and Martin to get in on the deal, are also planning to steal the diamond.<br /><br />How each pair of thieves plans out the heist is a thrill to watch. Things go awry, as Martin and Mandy unknowingly find themselves a step behind Lucy and Tommy.<br /><br />You'll find yourself rooting for these thieves as they find that they need each other to stay alive from the crime syndicate, who are not happy at all that the diamond is not in its hands.<br /><br />Action fans will not be disappointed, as there's a healthy dose of gun battles, martial arts, and hand-to-hand combat sequences.<br /><br />What is surprising is that, it's not just the action that carries this film, but the romance and laughs (and I don't mean your typical one-liners prevalent in action films) that sneak in.<br /><br />It's not easy to root for bad guys, but we get to see the human side of these thieves and the chemistry they develop.<br /><br />A great film and one NOT to miss!<br /><br />9 out of 10 \n",
            "\n",
            "Label : \n",
            "pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def PreProcessingText(input_sentence):\n",
        "    input_sentence = input_sentence.lower() # 소문자화\n",
        "    input_sentence = re.sub('<[^>]*>', repl= ' ', string = input_sentence) # \"<br />\" 처리\n",
        "    input_sentence = re.sub('[!\"#$%&\\()*+,-./:;<=>?@[\\\\]^_`{|}~]', repl= ' ', string = input_sentence) # 특수문자 처리 (\"'\" 제외)\n",
        "    input_sentence = re.sub('\\s+', repl= ' ', string = input_sentence) # 연속된 띄어쓰기 처리\n",
        "    if input_sentence:\n",
        "        return input_sentence"
      ],
      "metadata": {
        "id": "WDiFUqOiBeBc"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example in train_data.examples:\n",
        "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()\n",
        "    \n",
        "for example in test_data.examples:\n",
        "    vars(example)['text'] = PreProcessingText(' '.join(vars(example)['text'])).split()"
      ],
      "metadata": {
        "id": "gDQWcZUJBeD3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {'emb_type' : 'glove', 'emb_dim' : 300}"
      ],
      "metadata": {
        "id": "x5eGzVQHBeG2"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making vocab\n",
        "TEXT.build_vocab(train_data,\n",
        "                 min_freq = 2, \n",
        "                 max_size = None,\n",
        "                 vectors = f\"glove.6B.{model_config['emb_dim']}d\")\n",
        "\n",
        "## vector list\n",
        "# charngram.100d\n",
        "# fasttext.en.300d\n",
        "# fasttext.simple.300d\n",
        "# glove.42B.300d\n",
        "# glove.840B.300d\n",
        "# glove.twitter.27B.25d\n",
        "# glove.twitter.27B.50d\n",
        "# glove.twitter.27B.100d\n",
        "# glove.twitter.27B.200d\n",
        "# glove.6B.50d\n",
        "# glove.6B.100d\n",
        "# glove.6B.200d\n",
        "# glove.6B.300d\n",
        "\n",
        "LABEL.build_vocab(train_data)\n",
        "\n",
        "model_config['vocab_size'] = len(TEXT.vocab)"
      ],
      "metadata": {
        "id": "pLJ9BDkxBeJ3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary Info\n",
        "print(f'Vocab Size : {len(TEXT.vocab)}')\n",
        "\n",
        "print('Vocab Examples : ')\n",
        "for idx, (k, v) in enumerate(TEXT.vocab.stoi.items()):\n",
        "    if idx >= 10:\n",
        "        break    \n",
        "    print('\\t', k, v)\n",
        "\n",
        "print('---------------------------------')\n",
        "\n",
        "# Label Info\n",
        "print(f'Label Size : {len(LABEL.vocab)}')\n",
        "\n",
        "print('Lable Examples : ')\n",
        "for idx, (k, v) in enumerate(LABEL.vocab.stoi.items()):\n",
        "    print('\\t', k, v)"
      ],
      "metadata": {
        "id": "SSeXOw1KBeMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "618b716a-349a-41db-ec85-d895150d0b52"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size : 51956\n",
            "Vocab Examples : \n",
            "\t [UNK] 0\n",
            "\t [PAD] 1\n",
            "\t the 2\n",
            "\t and 3\n",
            "\t a 4\n",
            "\t of 5\n",
            "\t to 6\n",
            "\t is 7\n",
            "\t in 8\n",
            "\t it 9\n",
            "---------------------------------\n",
            "Label Size : 2\n",
            "Lable Examples : \n",
            "\t neg 0\n",
            "\t pos 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check embedding vectors\n",
        "TEXT.vocab.vectors.shape"
      ],
      "metadata": {
        "id": "yRoHKzuWBqTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbb6b4d-4ed0-437c-92a2-e2a0840f21f6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([51956, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Spliting Valid set\n",
        "train_data, valid_data = train_data.split(random_state = random.seed(0),\n",
        "                                          split_ratio=0.8)"
      ],
      "metadata": {
        "id": "34XemuwDBqWg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['batch_size'] = 30\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_size=model_config['batch_size'],\n",
        "    device=device)"
      ],
      "metadata": {
        "id": "6HlVYVCyBqZq"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check batch data\n",
        "sample_for_check = next(iter(train_iterator))\n",
        "print(sample_for_check)\n",
        "print(sample_for_check.text)\n",
        "print(sample_for_check.label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTdT1RnEF3hk",
        "outputId": "b6420825-8211-4826-f50f-8c797bd1fb5e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[torchtext.data.batch.Batch of size 30]\n",
            "\t[.text]:[torch.cuda.LongTensor of size 30x500 (GPU 0)]\n",
            "\t[.label]:[torch.cuda.FloatTensor of size 30 (GPU 0)]\n",
            "tensor([[    1,     1,     1,  ...,   275,     5,   260],\n",
            "        [    1,     1,     1,  ...,    58,     0,     0],\n",
            "        [    1,     1,     1,  ...,   203,   220,   554],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,    98,    82,    17],\n",
            "        [    1,     1,     1,  ...,  9169, 12922,  4930],\n",
            "        [    1,     1,     1,  ..., 26492,  1977,  3791]], device='cuda:0')\n",
            "tensor([0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.,\n",
            "        0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check reverting data\n",
        "print(' '.join([TEXT.vocab.itos[int(x)] for x in sample_for_check.text[0,:] if x not in [0,1]]))\n",
        "print(LABEL.vocab.itos[int(sample_for_check.label[0])]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGDLngM5F3j6",
        "outputId": "d2ffffd0-dd89-407e-dc64-2e74bf285a75"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when you get your hands on a british film you expect some sort of quality and when it comes to acting camera work lighting etc this film does the business it's done by highly skilled craftsmen that alone can bring you an enjoyable one and a half hours but when you look under the layers of professionalism you don't really find anything apart from making you feel good and advocate a drug liberal view there's really nothing there the script is mediocre the plot is predictable and the ending must be one of the worst east of hollywood in all it's english it's just a shameful and cynical attempt to make another full monty why they made this film i haven't got a clue apart from making money of course\n",
            "neg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceClassification(nn.Module):\n",
        "    def __init__(self, **model_config):\n",
        "        super(SentenceClassification, self).__init__()\n",
        "\n",
        "        if model_config['emb_type'] == 'glove' or 'fasttext':\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'],\n",
        "                                    _weight = TEXT.vocab.vectors)\n",
        "        else:\n",
        "            self.emb = nn.Embedding(model_config['vocab_size'],\n",
        "                                    model_config['emb_dim'])\n",
        "        \n",
        "        self.bidirectional = model_config['bidirectional']\n",
        "        self.num_direction = 2 if model_config['bidirectional'] else 1\n",
        "        self.model_type = model_config['model_type'] \n",
        "\n",
        "        self.RNN = nn.RNN (input_size = model_config['emb_dim'],\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'],\n",
        "                           bidirectional = model_config['bidirectional'],\n",
        "                           batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.LSTM= nn.LSTM(input_size = model_config['emb_dim'],\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'],\n",
        "                           bidirectional = model_config['bidirectional'],\n",
        "                           batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.GRU = nn.GRU (input_size = model_config['emb_dim'],\n",
        "                           hidden_size = model_config['hidden_dim'],\n",
        "                           dropout=model_config['dropout'],\n",
        "                           bidirectional = model_config['bidirectional'],\n",
        "                           batch_first = model_config['batch_first'])\n",
        "        \n",
        "        self.fc = nn.Linear(model_config['hidden_dim'] * self.num_direction,\n",
        "                            model_config['output_dim'])\n",
        "        \n",
        "        self.drop = nn.Dropout(model_config['dropout'])\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        emb = self.emb(x) \n",
        "        # emb : (Batch_Size, Max_Seq_Length, Emb_dim)\n",
        "\n",
        "        if self.model_type == 'RNN':\n",
        "            output, hidden = self.RNN(emb) \n",
        "        elif self.model_type == 'LSTM':\n",
        "            output, (hidden, cell) = self.LSTM(emb)\n",
        "        elif self.model_type == 'GRU':\n",
        "            output, hidden = self.GRU(emb)\n",
        "        else:\n",
        "            raise NameError('Select model_type in [RNN, LSTM, GRU]')\n",
        "        \n",
        "        # output : (Batch_Size, Max_Seq_Length, Hidden_dim * num_direction) \n",
        "        # hidden : (num_direction, Batch_Size, Hidden_dim)\n",
        "        \n",
        "        last_output = output[:,-1,:]\n",
        "\n",
        "        # last_output : (Batch_Size, Hidden_dim * num_direction)\n",
        "        return self.fc(self.drop(last_output))"
      ],
      "metadata": {
        "id": "C-Agk5u9F3md"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config.update(dict(batch_first = True,\n",
        "                         model_type = 'RNN',\n",
        "                         bidirectional = True,\n",
        "                         hidden_dim = 128,\n",
        "                         output_dim = 1,\n",
        "                         dropout = 0))"
      ],
      "metadata": {
        "id": "Uz0JzMZnGFum"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceClassification(**model_config).to(device)"
      ],
      "metadata": {
        "id": "cTjhY67lGFxG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.forward(sample_for_check.text).squeeze()"
      ],
      "metadata": {
        "id": "X1Yu8A5PGFz2"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.BCEWithLogitsLoss().to(device)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "metadata": {
        "id": "2MHm2ybLGF2s"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss = loss_fn(predictions, sample_for_check.label)\n",
        "acc = binary_accuracy(predictions, sample_for_check.label)"
      ],
      "metadata": {
        "id": "6fEzHwVEGOYb"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "print(loss, acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKJ7aKeqGOat",
        "outputId": "79164435-7345-47e5-d863-cec8e2c00d2e"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.1703,  0.0098, -0.2055, -0.0231,  0.0826, -0.0016, -0.0780, -0.1905,\n",
            "         0.0180, -0.0034, -0.1470, -0.1159, -0.5296, -0.1090, -0.0193, -0.0725,\n",
            "        -0.3045, -0.0887, -0.1807, -0.0810,  0.0352,  0.0361, -0.3563, -0.1840,\n",
            "         0.1674,  0.0008,  0.0846,  0.1702, -0.0997,  0.1138], device='cuda:0',\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "tensor(0.6688, device='cuda:0', grad_fn=<BinaryCrossEntropyWithLogitsBackward>) tensor(0.7000, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, iterator, optimizer, loss_fn, idx_epoch, **model_params):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train() \n",
        "    batch_size = model_params['batch_size']\n",
        "\n",
        "    for idx, batch in enumerate(iterator):\n",
        "        \n",
        "        # Initializing\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Forward \n",
        "        predictions = model(batch.text).squeeze()\n",
        "        loss = loss_fn(predictions, batch.label)\n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        sys.stdout.write(\n",
        "                    \"\\r\" + f\"[Train] Epoch : {idx_epoch:^3}\"\\\n",
        "                    f\"[{(idx + 1) * batch_size} / {len(iterator) * batch_size} ({100. * (idx + 1) / len(iterator) :.4}%)]\"\\\n",
        "                    f\"  Loss: {loss.item():.4}\"\\\n",
        "                    f\"  Acc : {acc.item():.4}\"\\\n",
        "                    )\n",
        "\n",
        "        # Backward \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Update Epoch Performance\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss/len(iterator) , epoch_acc/len(iterator) "
      ],
      "metadata": {
        "id": "fJ7wTQJRGOdJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, iterator, loss_fn):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # evaluation mode\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            predictions = model(batch.text).squeeze(1)\n",
        "            loss = loss_fn(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "metadata": {
        "id": "rv07v129GZoE"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['model_type'] = 'RNN'\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "jaQwDrbzGZqY"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "N_EPOCH = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
        "        print(f'\\t Saved at {epoch}-epoch')\n",
        "\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnDF3M8PGZsp",
        "outputId": "97e9a9c1-83e2-470c-93bf-803ebf2f9e15"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Model name : bi-RNN_glove\n",
            "---------------------------------\n",
            "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.4356  Acc : 0.8\n",
            "\t Saved at 0-epoch\n",
            "\t Epoch : 0 | Train Loss : 0.6133 | Train Acc : 0.6602\n",
            "\t Epoch : 0 | Valid Loss : 0.5663 | Valid Acc : 0.7182\n",
            "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.577  Acc : 0.7333\n",
            "\t Epoch : 1 | Train Loss : 0.5549 | Train Acc : 0.7154\n",
            "\t Epoch : 1 | Valid Loss : 0.5786 | Valid Acc : 0.7084\n",
            "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.3948  Acc : 0.8333\n",
            "\t Epoch : 2 | Train Loss : 0.4282 | Train Acc : 0.8051\n",
            "\t Epoch : 2 | Valid Loss : 0.636 | Valid Acc : 0.6554\n",
            "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.1862  Acc : 0.9667\n",
            "\t Epoch : 3 | Train Loss : 0.4199 | Train Acc : 0.807\n",
            "\t Epoch : 3 | Valid Loss : 0.6079 | Valid Acc : 0.7326\n",
            "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.2315  Acc : 0.9\n",
            "\t Epoch : 4 | Train Loss : 0.3042 | Train Acc : 0.8785\n",
            "\t Epoch : 4 | Valid Loss : 0.5847 | Valid Acc : 0.7562\n",
            "CPU times: user 5min 30s, sys: 1.96 s, total: 5min 31s\n",
            "Wall time: 5min 31s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
        "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_iMFtO5F3pZ",
        "outputId": "da9619dd-8d33-4e69-a068-1b1e1d73451f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.5711 | Test Acc : 0.7154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['model_type'] = 'LSTM'\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "PAOhGdnuKDQZ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "N_EPOCH = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
        "        print(f'\\t Saved at {epoch}-epoch')\n",
        "\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP7IWCwQKDTP",
        "outputId": "5db4edbd-f11e-4f54-86c4-fdf04908de13"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Model name : bi-LSTM_glove\n",
            "---------------------------------\n",
            "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.2032  Acc : 0.9333\n",
            "\t Saved at 0-epoch\n",
            "\t Epoch : 0 | Train Loss : 0.408 | Train Acc : 0.8242\n",
            "\t Epoch : 0 | Valid Loss : 0.3361 | Valid Acc : 0.8616\n",
            "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.2105  Acc : 0.9333\n",
            "\t Epoch : 1 | Train Loss : 0.1922 | Train Acc : 0.9309\n",
            "\t Epoch : 1 | Valid Loss : 0.3484 | Valid Acc : 0.8654\n",
            "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.02001  Acc : 1.0\n",
            "\t Epoch : 2 | Train Loss : 0.06827 | Train Acc : 0.9781\n",
            "\t Epoch : 2 | Valid Loss : 0.4313 | Valid Acc : 0.8656\n",
            "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.008021  Acc : 1.0\n",
            "\t Epoch : 3 | Train Loss : 0.01949 | Train Acc : 0.9953\n",
            "\t Epoch : 3 | Valid Loss : 0.5766 | Valid Acc : 0.8605\n",
            "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.01229  Acc : 1.0\n",
            "\t Epoch : 4 | Train Loss : 0.009919 | Train Acc : 0.9978\n",
            "\t Epoch : 4 | Valid Loss : 0.5877 | Valid Acc : 0.8492\n",
            "CPU times: user 6min 53s, sys: 2.65 s, total: 6min 55s\n",
            "Wall time: 6min 54s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
        "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hgYP2u2KDWF",
        "outputId": "25c961db-61fd-47bc-e919-bf44fda1349a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.3463 | Test Acc : 0.8524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['model_type'] = 'GRU'\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "loss_fn = nn.BCEWithLogitsLoss().to(device)"
      ],
      "metadata": {
        "id": "-VA-Fo1KKV19"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "N_EPOCH = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "model_name = f\"{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}\"\n",
        "\n",
        "print('---------------------------------')\n",
        "print(f'Model name : {model_name}')\n",
        "print('---------------------------------')\n",
        "\n",
        "for epoch in range(N_EPOCH):\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, loss_fn, epoch, **model_config)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, loss_fn)\n",
        "    print('')\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), f'./{model_name}.pt')\n",
        "        print(f'\\t Saved at {epoch}-epoch')\n",
        "\n",
        "    print(f'\\t Epoch : {epoch} | Train Loss : {train_loss:.4} | Train Acc : {train_acc:.4}')\n",
        "    print(f'\\t Epoch : {epoch} | Valid Loss : {valid_loss:.4} | Valid Acc : {valid_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9scMn2fSKV4x",
        "outputId": "7ad99028-60bd-4f36-d276-b697429e3e2b"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "Model name : bi-GRU_glove\n",
            "---------------------------------\n",
            "[Train] Epoch :  0 [20010 / 20010 (100.0%)]  Loss: 0.34  Acc : 0.9333\n",
            "\t Saved at 0-epoch\n",
            "\t Epoch : 0 | Train Loss : 0.3869 | Train Acc : 0.819\n",
            "\t Epoch : 0 | Valid Loss : 0.241 | Valid Acc : 0.8996\n",
            "[Train] Epoch :  1 [20010 / 20010 (100.0%)]  Loss: 0.1413  Acc : 0.9333\n",
            "\t Epoch : 1 | Train Loss : 0.1392 | Train Acc : 0.9501\n",
            "\t Epoch : 1 | Valid Loss : 0.3141 | Valid Acc : 0.8799\n",
            "[Train] Epoch :  2 [20010 / 20010 (100.0%)]  Loss: 0.1358  Acc : 0.9667\n",
            "\t Epoch : 2 | Train Loss : 0.03612 | Train Acc : 0.989\n",
            "\t Epoch : 2 | Valid Loss : 0.4118 | Valid Acc : 0.8834\n",
            "[Train] Epoch :  3 [20010 / 20010 (100.0%)]  Loss: 0.02405  Acc : 0.9667\n",
            "\t Epoch : 3 | Train Loss : 0.008606 | Train Acc : 0.998\n",
            "\t Epoch : 3 | Valid Loss : 0.5333 | Valid Acc : 0.8858\n",
            "[Train] Epoch :  4 [20010 / 20010 (100.0%)]  Loss: 0.001785  Acc : 1.0\n",
            "\t Epoch : 4 | Train Loss : 0.003652 | Train Acc : 0.9995\n",
            "\t Epoch : 4 | Valid Loss : 0.5968 | Valid Acc : 0.8792\n",
            "CPU times: user 6min 41s, sys: 2.67 s, total: 6min 44s\n",
            "Wall time: 6min 42s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test set\n",
        "model.load_state_dict(torch.load(f'./{model_name}.pt'))\n",
        "test_loss, test_acc = evaluate(model, test_iterator, loss_fn)\n",
        "print(f'Test Loss : {test_loss:.4} | Test Acc : {test_acc:.4}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHoym82NKV7V",
        "outputId": "05cb5bdd-399d-4594-ea88-11df4648f276"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss : 0.2598 | Test Acc : 0.8933\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_config['model_type'] = 'GRU'\n",
        "model = SentenceClassification(**model_config).to(device)\n",
        "model.load_state_dict(torch.load(f\"./{'bi-' if model_config['bidirectional'] else ''}{model_config['model_type']}_{model_config['emb_type']}.pt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2gfEDz3KV93",
        "outputId": "ba067a18-1dd2-434c-892b-316a7b5aa8ff"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "    model.eval()\n",
        "    indexed = TEXT.numericalize(TEXT.pad([TEXT.tokenize(PreProcessingText(sentence))]))\n",
        "    input_data = torch.LongTensor(indexed).to(device)\n",
        "    prediction = torch.sigmoid(model(input_data))\n",
        "    return prediction.item()"
      ],
      "metadata": {
        "id": "EHEWas_0Osok"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = 'this movie is FUN'\n",
        "predict_sentiment(model = model, sentence = test_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xe6AD7COssX",
        "outputId": "0418fcea-dc69-41bf-977c-4daf5c30cd92"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.858779788017273"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tTct8fGmKDbw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}